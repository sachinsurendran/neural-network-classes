<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>Flood: G:/Documents/Flood/Flood/ObjectiveFunctional/SumSquaredError.cpp Source File</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.5 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
<h1>G:/Documents/Flood/Flood/ObjectiveFunctional/SumSquaredError.cpp</h1><a href="_sum_squared_error_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00002"></a>00002 <span class="comment">/*                                                                                                              */</span>
<a name="l00003"></a>00003 <span class="comment">/*   Flood: An Open Source Neural Networks C++ Library                                                          */</span>
<a name="l00004"></a>00004 <span class="comment">/*   www.cimne.com/flood                                                                                        */</span>
<a name="l00005"></a>00005 <span class="comment">/*                                                                                                              */</span>
<a name="l00006"></a>00006 <span class="comment">/*   S U M   S Q U A R E D   E R R O R   C L A S S                                                              */</span>
<a name="l00007"></a>00007 <span class="comment">/*                                                                                                              */</span>
<a name="l00008"></a>00008 <span class="comment">/*   Roberto Lopez                                                                                              */</span>
<a name="l00009"></a>00009 <span class="comment">/*   International Center for Numerical Methods in Engineering (CIMNE)                                          */</span>
<a name="l00010"></a>00010 <span class="comment">/*   Technical University of Catalonia (UPC)                                                                    */</span>
<a name="l00011"></a>00011 <span class="comment">/*   Barcelona, Spain                                                                                           */</span>
<a name="l00012"></a>00012 <span class="comment">/*   E-mail: rlopez@cimne.upc.edu                                                                               */</span>
<a name="l00013"></a>00013 <span class="comment">/*                                                                                                              */</span>
<a name="l00014"></a>00014 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00015"></a>00015 
<a name="l00016"></a>00016 <span class="preprocessor">#include &lt;iostream&gt;</span>
<a name="l00017"></a>00017 <span class="preprocessor">#include &lt;fstream&gt;</span>
<a name="l00018"></a>00018 <span class="preprocessor">#include &lt;math.h&gt;</span>
<a name="l00019"></a>00019 
<a name="l00020"></a>00020 <span class="preprocessor">#include "<a class="code" href="_sum_squared_error_8h.html">SumSquaredError.h</a>"</span>
<a name="l00021"></a>00021 
<a name="l00022"></a>00022 <span class="keyword">namespace </span>Flood
<a name="l00023"></a>00023 {
<a name="l00024"></a>00024 
<a name="l00025"></a>00025 <span class="comment">// GENERAL CONSTRUCTOR</span>
<a name="l00026"></a>00026 
<a name="l00041"></a>00041 
<a name="l00042"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#612a05a884bca5ea0bef956b4a886c3d">00042</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#eae157f224e6d41474f149ec235f540c">SumSquaredError::SumSquaredError</a>(<a class="code" href="class_flood_1_1_multilayer_perceptron.html">MultilayerPerceptron</a>* newMultilayerPerceptron, 
<a name="l00043"></a>00043 <a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* newInputTargetDataSet): <a class="code" href="class_flood_1_1_objective_functional.html">ObjectiveFunctional</a>(newMultilayerPerceptron)
<a name="l00044"></a>00044 {
<a name="l00045"></a>00045    <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a> = newInputTargetDataSet;
<a name="l00046"></a>00046 }
<a name="l00047"></a>00047 
<a name="l00048"></a>00048 
<a name="l00049"></a>00049 <span class="comment">// DEFAULT CONSTRUCTOR</span>
<a name="l00050"></a>00050 
<a name="l00062"></a>00062 
<a name="l00063"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#eae157f224e6d41474f149ec235f540c">00063</a> SumSquaredError::SumSquaredError(<span class="keywordtype">void</span>) : <a class="code" href="class_flood_1_1_objective_functional.html">ObjectiveFunctional</a>()
<a name="l00064"></a>00064 {
<a name="l00065"></a>00065    <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a> = NULL;
<a name="l00066"></a>00066 }
<a name="l00067"></a>00067 
<a name="l00068"></a>00068 
<a name="l00069"></a>00069 <span class="comment">// DESTRUCTOR</span>
<a name="l00070"></a>00070 <span class="comment">//</span>
<a name="l00072"></a>00072 <span class="comment"></span>
<a name="l00073"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#0a3e375036d47780a18587bd26915ea5">00073</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#0a3e375036d47780a18587bd26915ea5" title="Destructor.">SumSquaredError::~SumSquaredError</a>(<span class="keywordtype">void</span>) 
<a name="l00074"></a>00074 {
<a name="l00075"></a>00075 
<a name="l00076"></a>00076 }
<a name="l00077"></a>00077 
<a name="l00078"></a>00078 
<a name="l00079"></a>00079 <span class="comment">// METHODS</span>
<a name="l00080"></a>00080 
<a name="l00081"></a>00081 <span class="comment">// InputTargetDataSet* getInputTargetDataSet(void) method</span>
<a name="l00082"></a>00082 
<a name="l00085"></a>00085 
<a name="l00086"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#cd168416451cf8e3566f110515807fe6">00086</a> <a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* <a class="code" href="class_flood_1_1_sum_squared_error.html#cd168416451cf8e3566f110515807fe6">SumSquaredError::getInputTargetDataSet</a>(<span class="keywordtype">void</span>)
<a name="l00087"></a>00087 {
<a name="l00088"></a>00088    <span class="keywordflow">return</span>(<a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>);
<a name="l00089"></a>00089 }
<a name="l00090"></a>00090 
<a name="l00091"></a>00091 
<a name="l00092"></a>00092 <span class="comment">// void setInputTargetDataSet(InputTargetDataSet*) method</span>
<a name="l00093"></a>00093 
<a name="l00097"></a>00097 
<a name="l00098"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#1f23641c23d918a1036c28a50bea2ae8">00098</a> <span class="keywordtype">void</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#1f23641c23d918a1036c28a50bea2ae8">SumSquaredError::setInputTargetDataSet</a>(<a class="code" href="class_flood_1_1_input_target_data_set.html">InputTargetDataSet</a>* newInputTargetDataSet)
<a name="l00099"></a>00099 {
<a name="l00100"></a>00100    <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a> = newInputTargetDataSet;
<a name="l00101"></a>00101 }
<a name="l00102"></a>00102 
<a name="l00103"></a>00103 
<a name="l00104"></a>00104 <span class="comment">// double calculateEvaluation(void) method</span>
<a name="l00105"></a>00105 
<a name="l00110"></a>00110 
<a name="l00111"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#b6de2f80f078ad45c1a9c8a6c3fa3691">00111</a> <span class="keywordtype">double</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#b6de2f80f078ad45c1a9c8a6c3fa3691">SumSquaredError::calculateEvaluation</a>(<span class="keywordtype">void</span>)
<a name="l00112"></a>00112 {
<a name="l00113"></a>00113    <span class="comment">// Control sentence (if debug)</span>
<a name="l00114"></a>00114 
<a name="l00115"></a>00115 <span class="preprocessor">   #ifndef NDEBUG </span>
<a name="l00116"></a>00116 <span class="preprocessor"></span>
<a name="l00117"></a>00117    <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a> == NULL)
<a name="l00118"></a>00118    {
<a name="l00119"></a>00119       std::cerr &lt;&lt; std::endl
<a name="l00120"></a>00120                 &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00121"></a>00121                 &lt;&lt; <span class="stringliteral">"double calculateEvaluation(void) method."</span> &lt;&lt; std::endl
<a name="l00122"></a>00122                 &lt;&lt; <span class="stringliteral">"Pointer to multilayer perceptron object cannot be NULL."</span> &lt;&lt; std::endl
<a name="l00123"></a>00123                 &lt;&lt; std::endl;
<a name="l00124"></a>00124 
<a name="l00125"></a>00125         exit(1);
<a name="l00126"></a>00126    }
<a name="l00127"></a>00127    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a> == NULL)
<a name="l00128"></a>00128    {
<a name="l00129"></a>00129       std::cerr &lt;&lt; std::endl
<a name="l00130"></a>00130                 &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00131"></a>00131                 &lt;&lt; <span class="stringliteral">"double calculateEvaluation(void) method."</span> &lt;&lt; std::endl
<a name="l00132"></a>00132                 &lt;&lt; <span class="stringliteral">"Pointer to input-target data set object cannot be NULL."</span> &lt;&lt; std::endl
<a name="l00133"></a>00133                 &lt;&lt; std::endl;
<a name="l00134"></a>00134 
<a name="l00135"></a>00135       exit(1);
<a name="l00136"></a>00136    }
<a name="l00137"></a>00137 
<a name="l00138"></a>00138 <span class="preprocessor">   #endif</span>
<a name="l00139"></a>00139 <span class="preprocessor"></span>
<a name="l00140"></a>00140    <span class="keywordtype">int</span> numberOfInputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f727b7059d919a636e04ca0692f0b8bd">getNumberOfInputs</a>();
<a name="l00141"></a>00141    <span class="keywordtype">int</span> numberOfOutputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#55eda41ce2ec7aa063e6854a13143d4a">getNumberOfOutputs</a>();
<a name="l00142"></a>00142 
<a name="l00143"></a>00143    <span class="keywordtype">int</span> numberOfSamples = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#f5d20749c6fe94e29dda02adb1f763d2" title="This method returns the number of samples in the input-target data set.">getNumberOfSamples</a>();
<a name="l00144"></a>00144 
<a name="l00145"></a>00145 <span class="preprocessor">   #ifndef NDEBUG </span>
<a name="l00146"></a>00146 <span class="preprocessor"></span>
<a name="l00147"></a>00147    <span class="keywordtype">int</span> numberOfInputVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#9006d1b87b0bb9590eb28439d9d953c4" title="This method returns the number of input variables of the input-target data set.">getNumberOfInputVariables</a>();
<a name="l00148"></a>00148    <span class="keywordtype">int</span> numberOfTargetVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#503d1eeb47faeb6415e4b3ec76dc4620" title="This method returns the number of target variables of the input-target data set.">getNumberOfTargetVariables</a>();
<a name="l00149"></a>00149 
<a name="l00150"></a>00150    <span class="keywordflow">if</span>(numberOfInputs != numberOfInputVariables || numberOfOutputs != numberOfTargetVariables)
<a name="l00151"></a>00151    {
<a name="l00152"></a>00152       std::cout &lt;&lt; std::endl
<a name="l00153"></a>00153                 &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00154"></a>00154                 &lt;&lt; <span class="stringliteral">"double calculateEvaluation(void) method."</span> &lt;&lt; std::endl
<a name="l00155"></a>00155                 &lt;&lt; <span class="stringliteral">"Number of inputs and outputs in multilayer perceptron must be equal to "</span> 
<a name="l00156"></a>00156                 &lt;&lt; <span class="stringliteral">"number of input and output variables in input-target data set."</span> 
<a name="l00157"></a>00157                 &lt;&lt; std::endl &lt;&lt; std::endl;
<a name="l00158"></a>00158 
<a name="l00159"></a>00159       exit(1);
<a name="l00160"></a>00160    }
<a name="l00161"></a>00161 
<a name="l00162"></a>00162 <span class="preprocessor">   #endif</span>
<a name="l00163"></a>00163 <span class="preprocessor"></span>
<a name="l00164"></a>00164    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; inputData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#55a414aad1000ba3df7a24fb9b60bc1d" title="This method returns a Matrix containing the input data of the data set.">getInputData</a>();
<a name="l00165"></a>00165    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; targetData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#dfa520af76ebbdd4344ba62de1072bb7" title="This method returns a Matrix containing the target data of the data set.">getTargetData</a>();
<a name="l00166"></a>00166 
<a name="l00167"></a>00167    <span class="comment">// Increment number of evaluations</span>
<a name="l00168"></a>00168 
<a name="l00169"></a>00169    <a class="code" href="class_flood_1_1_objective_functional.html#c939d1683b74021c4149c3c5bc65d4fe">numberOfEvaluations</a>++;
<a name="l00170"></a>00170 
<a name="l00171"></a>00171    <span class="keywordtype">double</span> sumSquaredError = 0;   
<a name="l00172"></a>00172 
<a name="l00173"></a>00173    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(numberOfInputs);
<a name="l00174"></a>00174    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(numberOfOutputs);
<a name="l00175"></a>00175    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target(numberOfOutputs);
<a name="l00176"></a>00176 
<a name="l00177"></a>00177    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; numberOfSamples; i++)
<a name="l00178"></a>00178    {
<a name="l00179"></a>00179       <span class="comment">// Input vector</span>
<a name="l00180"></a>00180 
<a name="l00181"></a>00181       input = inputData.<a class="code" href="class_flood_1_1_matrix.html#f357ced2467777941490e3ae1982f6d3" title="This method returns the row i of the matrix.">getRow</a>(i);
<a name="l00182"></a>00182 
<a name="l00183"></a>00183       <span class="comment">// Output vector</span>
<a name="l00184"></a>00184 
<a name="l00185"></a>00185       output = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#493a7a9c89c4f9de4819c102e09fa717">calculateOutput</a>(input);
<a name="l00186"></a>00186 
<a name="l00187"></a>00187       <span class="comment">// Target vector</span>
<a name="l00188"></a>00188 
<a name="l00189"></a>00189      target = targetData.<a class="code" href="class_flood_1_1_matrix.html#f357ced2467777941490e3ae1982f6d3" title="This method returns the row i of the matrix.">getRow</a>(i);
<a name="l00190"></a>00190 
<a name="l00191"></a>00191       <span class="comment">// Sum of squares error</span>
<a name="l00192"></a>00192 
<a name="l00193"></a>00193       sumSquaredError += (output - target).dot(output - target);           
<a name="l00194"></a>00194    }
<a name="l00195"></a>00195 
<a name="l00196"></a>00196    <span class="keywordflow">return</span>(sumSquaredError);
<a name="l00197"></a>00197 }
<a name="l00198"></a>00198 
<a name="l00199"></a>00199 
<a name="l00200"></a>00200 <span class="comment">// Vector&lt;double&gt; calculateGradient(void)</span>
<a name="l00201"></a>00201 
<a name="l00206"></a>00206 
<a name="l00207"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#c7072778cebb86cc589c5564c79688b0">00207</a> <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#c7072778cebb86cc589c5564c79688b0">SumSquaredError::calculateGradient</a>(<span class="keywordtype">void</span>)
<a name="l00208"></a>00208 {
<a name="l00209"></a>00209    <span class="comment">// Multilayer perceptron </span>
<a name="l00210"></a>00210 
<a name="l00211"></a>00211    <span class="keywordtype">int</span> numberOfInputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f727b7059d919a636e04ca0692f0b8bd">getNumberOfInputs</a>();
<a name="l00212"></a>00212 
<a name="l00213"></a>00213    <span class="keywordtype">int</span> numberOfHiddenLayers = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#dcf52407622a350817f14945aa208b70">getNumberOfHiddenLayers</a>();
<a name="l00214"></a>00214    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;int&gt;</a> numbersOfHiddenNeurons = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d11c45b16073c2348a70a2cc79cc4637">getNumbersOfHiddenNeurons</a>();
<a name="l00215"></a>00215 
<a name="l00216"></a>00216    <span class="keywordtype">int</span> numberOfOutputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#55eda41ce2ec7aa063e6854a13143d4a">getNumberOfOutputs</a>();
<a name="l00217"></a>00217 
<a name="l00218"></a>00218    <a class="code" href="class_flood_1_1_multilayer_perceptron.html#b7d7995eda5851f6cde6af2968a52fcd">MultilayerPerceptron::PreAndPostProcessingMethod</a> preAndPostProcessingMethod
<a name="l00219"></a>00219    = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d09f2baf46a3d7f256e93e021fdcee66">getPreAndPostProcessingMethod</a>();
<a name="l00220"></a>00220 
<a name="l00221"></a>00221    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> meanOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f8f5cd5cccae2170f774d6bb9b5a765e">getMeanOfOutputVariables</a>();
<a name="l00222"></a>00222    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> standardDeviationOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#8bfb3bb7c420d60a98350f7e50d4704d">getStandardDeviationOfOutputVariables</a>();
<a name="l00223"></a>00223 
<a name="l00224"></a>00224    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> minimumOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7b1972a6d053379c1d245d08f50c0a7d">getMinimumOfOutputVariables</a>();
<a name="l00225"></a>00225    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> maximumOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#74cc18002177c9082ef16e4925a0e3d1">getMaximumOfOutputVariables</a>();
<a name="l00226"></a>00226 
<a name="l00227"></a>00227    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;Perceptron&gt;</a>&amp; outputLayer = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#8b120751f1d5a42ce9eed5f84236598c">getOutputLayer</a>();
<a name="l00228"></a>00228    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;Perceptron&gt;</a> &gt;&amp; hiddenLayers = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#311f5325b9148482154f81e5397dc34f">getHiddenLayers</a>();
<a name="l00229"></a>00229 
<a name="l00230"></a>00230    <span class="keywordtype">int</span> numberOfNeuralParameters = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#0a8cf51981e66e3b4992940506efbde6">getNumberOfNeuralParameters</a>();
<a name="l00231"></a>00231    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> synapticWeights;
<a name="l00232"></a>00232 
<a name="l00233"></a>00233    <span class="comment">// Input-target data set</span>
<a name="l00234"></a>00234 
<a name="l00235"></a>00235    <span class="keywordtype">int</span> numberOfSamples = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#f5d20749c6fe94e29dda02adb1f763d2" title="This method returns the number of samples in the input-target data set.">getNumberOfSamples</a>();
<a name="l00236"></a>00236    <span class="keywordtype">int</span> numberOfTargetVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#503d1eeb47faeb6415e4b3ec76dc4620" title="This method returns the number of target variables of the input-target data set.">getNumberOfTargetVariables</a>();
<a name="l00237"></a>00237 
<a name="l00238"></a>00238    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; inputData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#55a414aad1000ba3df7a24fb9b60bc1d" title="This method returns a Matrix containing the input data of the data set.">getInputData</a>();
<a name="l00239"></a>00239    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; targetData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#dfa520af76ebbdd4344ba62de1072bb7" title="This method returns a Matrix containing the target data of the data set.">getTargetData</a>();
<a name="l00240"></a>00240 
<a name="l00241"></a>00241    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target(numberOfTargetVariables);
<a name="l00242"></a>00242 
<a name="l00243"></a>00243    <span class="comment">// Input, outputs, gradient</span>
<a name="l00244"></a>00244 
<a name="l00245"></a>00245    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(numberOfInputs);
<a name="l00246"></a>00246    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> inputSignal(numberOfInputs);
<a name="l00247"></a>00247    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; netInputSignalToHiddenLayer(numberOfHiddenLayers);
<a name="l00248"></a>00248    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; outputSignalFromHiddenLayer(numberOfHiddenLayers);
<a name="l00249"></a>00249    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; outputSignalDerivativeFromHiddenLayer(numberOfHiddenLayers);
<a name="l00250"></a>00250    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> netInputSignalToOutputLayer(numberOfOutputs);
<a name="l00251"></a>00251    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> outputSignal(numberOfOutputs);
<a name="l00252"></a>00252    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(numberOfOutputs);
<a name="l00253"></a>00253    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> gradient(numberOfNeuralParameters, 0.0);
<a name="l00254"></a>00254 
<a name="l00255"></a>00255    <span class="comment">// Output and hidden errors</span>
<a name="l00256"></a>00256 
<a name="l00257"></a>00257    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> outputError(numberOfOutputs);
<a name="l00258"></a>00258    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; hiddenError(numberOfHiddenLayers);
<a name="l00259"></a>00259 
<a name="l00260"></a>00260    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = 0; h &lt; numberOfHiddenLayers; h++)
<a name="l00261"></a>00261    {
<a name="l00262"></a>00262       hiddenError[h].<a class="code" href="class_flood_1_1_vector.html#5b17ad8d2a835043d6c991654b764778">setSize</a>(numbersOfHiddenNeurons[h]);
<a name="l00263"></a>00263    }
<a name="l00264"></a>00264 
<a name="l00265"></a>00265    <span class="comment">// Main loop</span>
<a name="l00266"></a>00266 
<a name="l00267"></a>00267    <span class="keywordtype">double</span> sum;
<a name="l00268"></a>00268    <span class="keywordtype">int</span> index;
<a name="l00269"></a>00269 
<a name="l00270"></a>00270    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> sample = 0; sample &lt; numberOfSamples; sample++)
<a name="l00271"></a>00271    {
<a name="l00272"></a>00272       <span class="comment">// Actual input</span>
<a name="l00273"></a>00273 
<a name="l00274"></a>00274       input = inputData.<a class="code" href="class_flood_1_1_matrix.html#f357ced2467777941490e3ae1982f6d3" title="This method returns the row i of the matrix.">getRow</a>(sample);
<a name="l00275"></a>00275 
<a name="l00276"></a>00276       <span class="comment">// Preprocess input to obtain input signal to the neural network </span>
<a name="l00277"></a>00277 
<a name="l00278"></a>00278       inputSignal = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d15b02cc6a5611b6d154b9ee8d67c39f">preprocessInput</a>(input);
<a name="l00279"></a>00279 
<a name="l00280"></a>00280       <span class="comment">// Calculate net input output and output signal derivative from all hidden layers</span>
<a name="l00281"></a>00281 
<a name="l00282"></a>00282       netInputSignalToHiddenLayer[0] 
<a name="l00283"></a>00283       = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#49f1323fbcd7e4fbe0fe61aaa4661f3a">calculateNetInputSignalToHiddenLayer</a>(0, inputSignal);
<a name="l00284"></a>00284 
<a name="l00285"></a>00285       outputSignalFromHiddenLayer[0] 
<a name="l00286"></a>00286       = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#be1cb61845f832240266ab6eeb27dcf0">calculateOutputSignalFromHiddenLayer</a>(0, netInputSignalToHiddenLayer[0]);
<a name="l00287"></a>00287 
<a name="l00288"></a>00288       outputSignalDerivativeFromHiddenLayer[0] 
<a name="l00289"></a>00289       = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#fb2e52b094458c94240c583a8fde433e">calculateOutputSignalDerivativeFromHiddenLayer</a>(0, netInputSignalToHiddenLayer[0]);
<a name="l00290"></a>00290   
<a name="l00291"></a>00291       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = 1; h &lt; numberOfHiddenLayers; h++)
<a name="l00292"></a>00292       {
<a name="l00293"></a>00293          netInputSignalToHiddenLayer[h] = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>
<a name="l00294"></a>00294          -&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#49f1323fbcd7e4fbe0fe61aaa4661f3a">calculateNetInputSignalToHiddenLayer</a>(h, outputSignalFromHiddenLayer[h-1]);
<a name="l00295"></a>00295    
<a name="l00296"></a>00296          outputSignalFromHiddenLayer[h] = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>
<a name="l00297"></a>00297          -&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#be1cb61845f832240266ab6eeb27dcf0">calculateOutputSignalFromHiddenLayer</a>(h, netInputSignalToHiddenLayer[h]);
<a name="l00298"></a>00298 
<a name="l00299"></a>00299          outputSignalDerivativeFromHiddenLayer[h] = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>
<a name="l00300"></a>00300          -&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#fb2e52b094458c94240c583a8fde433e">calculateOutputSignalDerivativeFromHiddenLayer</a>(h, netInputSignalToHiddenLayer[h]);         
<a name="l00301"></a>00301       }
<a name="l00302"></a>00302 
<a name="l00303"></a>00303       <span class="comment">// Get net input signal to output layer</span>
<a name="l00304"></a>00304 
<a name="l00305"></a>00305       netInputSignalToOutputLayer = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>
<a name="l00306"></a>00306       -&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#3ca2638a68021cf33045c44b122a36b5">calculateNetInputSignalToOutputLayer</a>(outputSignalFromHiddenLayer[numberOfHiddenLayers-1]);
<a name="l00307"></a>00307 
<a name="l00308"></a>00308       <span class="comment">// Get actual output signal from output layer</span>
<a name="l00309"></a>00309 
<a name="l00310"></a>00310       <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> outputSignal = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#69f1a5a6fb13814334dcd6c448e35be8">calculateOutputSignal</a>(netInputSignalToOutputLayer);
<a name="l00311"></a>00311 
<a name="l00312"></a>00312       <span class="comment">// Get actual output signal derivative from output layer</span>
<a name="l00313"></a>00313 
<a name="l00314"></a>00314       <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> outputSignalDerivative
<a name="l00315"></a>00315       = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#3ae644ff7d78606aff14f08d398d7669">calculateOutputSignalDerivative</a>(netInputSignalToOutputLayer);
<a name="l00316"></a>00316 
<a name="l00317"></a>00317       <span class="comment">// Postprocess output signal from the neural network to get output</span>
<a name="l00318"></a>00318 
<a name="l00319"></a>00319       <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#77a4a34c9bb097a0c0720875e810bc81">postprocessOutputSignal</a>(outputSignal);
<a name="l00320"></a>00320 
<a name="l00321"></a>00321       <span class="comment">// Actual target</span>
<a name="l00322"></a>00322 
<a name="l00323"></a>00323       <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target = targetData.<a class="code" href="class_flood_1_1_matrix.html#f357ced2467777941490e3ae1982f6d3" title="This method returns the row i of the matrix.">getRow</a>(sample);
<a name="l00324"></a>00324 
<a name="l00325"></a>00325       <span class="comment">// Evaluate the error for all the output units      </span>
<a name="l00326"></a>00326 
<a name="l00327"></a>00327       <span class="keywordflow">switch</span>(preAndPostProcessingMethod)
<a name="l00328"></a>00328       {
<a name="l00329"></a>00329          <span class="keywordflow">case</span> <a class="code" href="class_flood_1_1_multilayer_perceptron.html#b7d7995eda5851f6cde6af2968a52fcd986c20db8f958cf20c89e19045bd4d39">MultilayerPerceptron::None</a>:
<a name="l00330"></a>00330          {   
<a name="l00331"></a>00331             outputError = outputSignalDerivative*(output-target)*2.0;
<a name="l00332"></a>00332          }<span class="comment">//end none   </span>
<a name="l00333"></a>00333 
<a name="l00334"></a>00334          <span class="keywordflow">break</span>;
<a name="l00335"></a>00335 
<a name="l00336"></a>00336          <span class="keywordflow">case</span> <a class="code" href="class_flood_1_1_multilayer_perceptron.html#b7d7995eda5851f6cde6af2968a52fcdac807f7507534fe2cf204ef315c6821a">MultilayerPerceptron::MeanAndStandardDeviation</a>:
<a name="l00337"></a>00337          {
<a name="l00338"></a>00338             outputError = outputSignalDerivative*(output-target)*standardDeviationOfOutputVariables*2.0;
<a name="l00339"></a>00339          }<span class="comment">//end mean and standard deviation</span>
<a name="l00340"></a>00340 
<a name="l00341"></a>00341          <span class="keywordflow">break</span>;
<a name="l00342"></a>00342 
<a name="l00343"></a>00343          <span class="keywordflow">case</span> <a class="code" href="class_flood_1_1_multilayer_perceptron.html#b7d7995eda5851f6cde6af2968a52fcdc890a6bd3b59fe15f9df14132b8ceff9">MultilayerPerceptron::MinimumAndMaximum</a>:
<a name="l00344"></a>00344          {
<a name="l00345"></a>00345             outputError = outputSignalDerivative*(output-target)*(maximumOfOutputVariables-minimumOfOutputVariables);
<a name="l00346"></a>00346          }<span class="comment">//end minimum and maximum              </span>
<a name="l00347"></a>00347 
<a name="l00348"></a>00348          <span class="keywordflow">break</span>;
<a name="l00349"></a>00349       }<span class="comment">//end switch</span>
<a name="l00350"></a>00350 
<a name="l00351"></a>00351       <span class="comment">// Backpropagate the output errors to obtain the hidden errors</span>
<a name="l00352"></a>00352 
<a name="l00353"></a>00353       <span class="comment">// Last hidden layer</span>
<a name="l00354"></a>00354 
<a name="l00355"></a>00355       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; numbersOfHiddenNeurons[numberOfHiddenLayers-1]; j++)
<a name="l00356"></a>00356       {
<a name="l00357"></a>00357          sum = 0.0;
<a name="l00358"></a>00358 
<a name="l00359"></a>00359          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; numberOfOutputs; k++)
<a name="l00360"></a>00360          {
<a name="l00361"></a>00361             synapticWeights = outputLayer[k].getSynapticWeights();
<a name="l00362"></a>00362             sum += (synapticWeights[j])*outputError[k];
<a name="l00363"></a>00363          }
<a name="l00364"></a>00364 
<a name="l00365"></a>00365          hiddenError[numberOfHiddenLayers-1][j] = outputSignalDerivativeFromHiddenLayer[numberOfHiddenLayers-1][j]*sum;
<a name="l00366"></a>00366       }
<a name="l00367"></a>00367 
<a name="l00368"></a>00368       <span class="comment">// Rest of hidden layers</span>
<a name="l00369"></a>00369 
<a name="l00370"></a>00370       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = numberOfHiddenLayers-2; h &gt;= 0; h--) 
<a name="l00371"></a>00371       {   
<a name="l00372"></a>00372          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; numbersOfHiddenNeurons[h]; j++)
<a name="l00373"></a>00373          {
<a name="l00374"></a>00374             sum = 0.0;
<a name="l00375"></a>00375 
<a name="l00376"></a>00376             <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; numbersOfHiddenNeurons[h+1]; k++)
<a name="l00377"></a>00377             {
<a name="l00378"></a>00378                synapticWeights = hiddenLayers[h+1][k].getSynapticWeights();
<a name="l00379"></a>00379                sum += (synapticWeights[j])*hiddenError[h+1][k];
<a name="l00380"></a>00380             }            
<a name="l00381"></a>00381           
<a name="l00382"></a>00382             hiddenError[h][j] = outputSignalDerivativeFromHiddenLayer[h][j]*sum;
<a name="l00383"></a>00383          }
<a name="l00384"></a>00384       }
<a name="l00385"></a>00385 
<a name="l00386"></a>00386       <span class="comment">// Calculate gradient elements</span>
<a name="l00387"></a>00387 
<a name="l00388"></a>00388       index = 0;
<a name="l00389"></a>00389 
<a name="l00390"></a>00390       <span class="comment">// Calculate gradient elements of hidden neurons</span>
<a name="l00391"></a>00391 
<a name="l00392"></a>00392       <span class="comment">// First hidden layer</span>
<a name="l00393"></a>00393 
<a name="l00394"></a>00394       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; numbersOfHiddenNeurons[0]; j++)
<a name="l00395"></a>00395       {
<a name="l00396"></a>00396          <span class="comment">// Bias</span>
<a name="l00397"></a>00397 
<a name="l00398"></a>00398          gradient[index] += hiddenError[0][j];
<a name="l00399"></a>00399          index++;
<a name="l00400"></a>00400 
<a name="l00401"></a>00401          <span class="comment">// Synaptic weights</span>
<a name="l00402"></a>00402 
<a name="l00403"></a>00403          synapticWeights = hiddenLayers[0][j].getSynapticWeights();
<a name="l00404"></a>00404 
<a name="l00405"></a>00405          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; numberOfInputs; k++)
<a name="l00406"></a>00406          {
<a name="l00407"></a>00407             gradient[index] += hiddenError[0][j]*inputSignal[k];
<a name="l00408"></a>00408             index++;   
<a name="l00409"></a>00409          }
<a name="l00410"></a>00410       }
<a name="l00411"></a>00411 
<a name="l00412"></a>00412       <span class="comment">// Rest of hidden layers  </span>
<a name="l00413"></a>00413     
<a name="l00414"></a>00414       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> h = 1; h &lt; numberOfHiddenLayers; h++)
<a name="l00415"></a>00415       {      
<a name="l00416"></a>00416          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; numbersOfHiddenNeurons[h]; j++)
<a name="l00417"></a>00417          {
<a name="l00418"></a>00418             <span class="comment">// Bias</span>
<a name="l00419"></a>00419 
<a name="l00420"></a>00420             gradient[index] += hiddenError[h][j];
<a name="l00421"></a>00421             index++;
<a name="l00422"></a>00422 
<a name="l00423"></a>00423             <span class="comment">// Synaptic weights</span>
<a name="l00424"></a>00424 
<a name="l00425"></a>00425             synapticWeights = hiddenLayers[h][j].getSynapticWeights();
<a name="l00426"></a>00426 
<a name="l00427"></a>00427             <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; numbersOfHiddenNeurons[h-1]; k++)
<a name="l00428"></a>00428             {
<a name="l00429"></a>00429                gradient[index] += hiddenError[h][j]*outputSignalFromHiddenLayer[h-1][k];
<a name="l00430"></a>00430                index++;   
<a name="l00431"></a>00431             }
<a name="l00432"></a>00432          }
<a name="l00433"></a>00433       }
<a name="l00434"></a>00434 
<a name="l00435"></a>00435       <span class="comment">// Calculate gradient elements of output neurons</span>
<a name="l00436"></a>00436 
<a name="l00437"></a>00437       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; numberOfOutputs; j++)
<a name="l00438"></a>00438       {
<a name="l00439"></a>00439          <span class="comment">// Bias</span>
<a name="l00440"></a>00440 
<a name="l00441"></a>00441          gradient[index] += outputError[j];
<a name="l00442"></a>00442          index++;
<a name="l00443"></a>00443 
<a name="l00444"></a>00444          <span class="comment">// Synaptic weights</span>
<a name="l00445"></a>00445 
<a name="l00446"></a>00446          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k = 0; k &lt; numbersOfHiddenNeurons[numberOfHiddenLayers-1]; k++)
<a name="l00447"></a>00447          {
<a name="l00448"></a>00448             gradient[index] += outputSignalFromHiddenLayer[numberOfHiddenLayers-1][k]*outputError[j];
<a name="l00449"></a>00449             index++;
<a name="l00450"></a>00450          }
<a name="l00451"></a>00451       }
<a name="l00452"></a>00452    }
<a name="l00453"></a>00453 
<a name="l00454"></a>00454    <span class="keywordflow">return</span>(gradient);
<a name="l00455"></a>00455 }
<a name="l00456"></a>00456 
<a name="l00457"></a>00457 
<a name="l00458"></a>00458 <span class="comment">// Matrix&lt;double&gt; calculateJacobian(void) method</span>
<a name="l00459"></a>00459 
<a name="l00467"></a>00467 
<a name="l00468"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#7861e34917159b07b25efbbd3d01a2c6">00468</a> <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#7861e34917159b07b25efbbd3d01a2c6">SumSquaredError::calculateJacobian</a>(<span class="keywordtype">void</span>)
<a name="l00469"></a>00469 {
<a name="l00470"></a>00470    <span class="comment">// Multilayer perceptron stuff</span>
<a name="l00471"></a>00471 
<a name="l00472"></a>00472    <span class="keywordtype">int</span> numberOfInputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f727b7059d919a636e04ca0692f0b8bd">getNumberOfInputs</a>();
<a name="l00473"></a>00473 
<a name="l00474"></a>00474    <span class="keywordtype">int</span> numberOfHiddenLayers = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#dcf52407622a350817f14945aa208b70">getNumberOfHiddenLayers</a>();
<a name="l00475"></a>00475    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;int&gt;</a> numbersOfHiddenNeurons = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d11c45b16073c2348a70a2cc79cc4637">getNumbersOfHiddenNeurons</a>();
<a name="l00476"></a>00476 
<a name="l00477"></a>00477    <span class="keywordtype">int</span> numberOfOutputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#55eda41ce2ec7aa063e6854a13143d4a">getNumberOfOutputs</a>();
<a name="l00478"></a>00478 
<a name="l00479"></a>00479    <a class="code" href="class_flood_1_1_multilayer_perceptron.html#b7d7995eda5851f6cde6af2968a52fcd">MultilayerPerceptron::PreAndPostProcessingMethod</a> preAndPostProcessingMethod
<a name="l00480"></a>00480    = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#d09f2baf46a3d7f256e93e021fdcee66">getPreAndPostProcessingMethod</a>();
<a name="l00481"></a>00481 
<a name="l00482"></a>00482    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> meanOfInputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f6eb1f51ed3993ca94f040dd63cd6a86">getMeanOfInputVariables</a>();
<a name="l00483"></a>00483    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> standardDeviationOfInputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#afc9bd6ddee63468610dab1e22bc62c6">getStandardDeviationOfInputVariables</a>();
<a name="l00484"></a>00484 
<a name="l00485"></a>00485    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> meanOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f8f5cd5cccae2170f774d6bb9b5a765e">getMeanOfOutputVariables</a>();
<a name="l00486"></a>00486    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> standardDeviationOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#8bfb3bb7c420d60a98350f7e50d4704d">getStandardDeviationOfOutputVariables</a>();
<a name="l00487"></a>00487 
<a name="l00488"></a>00488    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> minimumOfInputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#6dff67b0188cd403b582d4b8979d341f">getMinimumOfInputVariables</a>();
<a name="l00489"></a>00489    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> maximumOfInputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#bc283eac581a2f0c2b5122f5544ba03a">getMaximumOfInputVariables</a>();
<a name="l00490"></a>00490 
<a name="l00491"></a>00491    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> minimumOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7b1972a6d053379c1d245d08f50c0a7d">getMinimumOfOutputVariables</a>();
<a name="l00492"></a>00492    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> maximumOfOutputVariables = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#74cc18002177c9082ef16e4925a0e3d1">getMaximumOfOutputVariables</a>();
<a name="l00493"></a>00493 
<a name="l00494"></a>00494    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;Perceptron&gt;</a>&amp; outputLayer = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#8b120751f1d5a42ce9eed5f84236598c">getOutputLayer</a>();
<a name="l00495"></a>00495    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;Perceptron&gt;</a> &gt;&amp; hiddenLayers = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#311f5325b9148482154f81e5397dc34f">getHiddenLayers</a>();
<a name="l00496"></a>00496 
<a name="l00497"></a>00497    <span class="keywordtype">int</span> numberOfNeuralParameters = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#0a8cf51981e66e3b4992940506efbde6">getNumberOfNeuralParameters</a>();
<a name="l00498"></a>00498 
<a name="l00499"></a>00499    <span class="comment">// Input-target data set stuff</span>
<a name="l00500"></a>00500 
<a name="l00501"></a>00501    <span class="keywordtype">int</span> numberOfSamples = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#f5d20749c6fe94e29dda02adb1f763d2" title="This method returns the number of samples in the input-target data set.">getNumberOfSamples</a>();
<a name="l00502"></a>00502    <span class="keywordtype">int</span> numberOfTargetVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#503d1eeb47faeb6415e4b3ec76dc4620" title="This method returns the number of target variables of the input-target data set.">getNumberOfTargetVariables</a>();
<a name="l00503"></a>00503 
<a name="l00504"></a>00504    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; inputData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#55a414aad1000ba3df7a24fb9b60bc1d" title="This method returns a Matrix containing the input data of the data set.">getInputData</a>();
<a name="l00505"></a>00505    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; targetData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#dfa520af76ebbdd4344ba62de1072bb7" title="This method returns a Matrix containing the target data of the data set.">getTargetData</a>();
<a name="l00506"></a>00506 
<a name="l00507"></a>00507    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target(numberOfTargetVariables);
<a name="l00508"></a>00508 
<a name="l00509"></a>00509    <span class="comment">// Back-popagation algorithm stuff</span>
<a name="l00510"></a>00510 
<a name="l00511"></a>00511    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(numberOfInputs);
<a name="l00512"></a>00512    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> inputSignal(numberOfInputs);
<a name="l00513"></a>00513    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; netInputSignalToHiddenLayer(numberOfHiddenLayers);
<a name="l00514"></a>00514    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; outputSignalFromHiddenLayer(numberOfHiddenLayers);
<a name="l00515"></a>00515    <a class="code" href="class_flood_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; outputSignalDerivativeFromHiddenLayer(numberOfHiddenLayers);
<a name="l00516"></a>00516    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> netInputSignalToOutputLayer(numberOfOutputs);
<a name="l00517"></a>00517    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> outputSignal(numberOfOutputs);
<a name="l00518"></a>00518    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(numberOfOutputs);
<a name="l00519"></a>00519 
<a name="l00520"></a>00520    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> gradient(numberOfNeuralParameters, 0.0);
<a name="l00521"></a>00521    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> jacobian(numberOfSamples, numberOfNeuralParameters);
<a name="l00522"></a>00522 <span class="comment">/*</span>
<a name="l00523"></a>00523 <span class="comment"></span>
<a name="l00524"></a>00524 <span class="comment">   Vector&lt;double&gt; outputError(numberOfOutputs);</span>
<a name="l00525"></a>00525 <span class="comment">   Vector&lt; Vector&lt;double&gt; &gt; hiddenError(numberOfHiddenLayers);</span>
<a name="l00526"></a>00526 <span class="comment"></span>
<a name="l00527"></a>00527 <span class="comment">   // Main loop</span>
<a name="l00528"></a>00528 <span class="comment"></span>
<a name="l00529"></a>00529 <span class="comment">   int index = 0;</span>
<a name="l00530"></a>00530 <span class="comment"></span>
<a name="l00531"></a>00531 <span class="comment">   for(int i = 0; i &lt; numberOfSamples; i++)</span>
<a name="l00532"></a>00532 <span class="comment">   {</span>
<a name="l00533"></a>00533 <span class="comment">      index = 0;</span>
<a name="l00534"></a>00534 <span class="comment"></span>
<a name="l00535"></a>00535 <span class="comment">      // Actual input</span>
<a name="l00536"></a>00536 <span class="comment"></span>
<a name="l00537"></a>00537 <span class="comment">      input = inputData.getRow(i);</span>
<a name="l00538"></a>00538 <span class="comment"></span>
<a name="l00539"></a>00539 <span class="comment">      // Preprocess input to obtain input signal to the neural network </span>
<a name="l00540"></a>00540 <span class="comment"></span>
<a name="l00541"></a>00541 <span class="comment">      inputSignal = multilayerPerceptron-&gt;preprocessInput(input);      </span>
<a name="l00542"></a>00542 <span class="comment"></span>
<a name="l00543"></a>00543 <span class="comment">      // Calculate net input output and output signal derivative from all hidden layers</span>
<a name="l00544"></a>00544 <span class="comment"></span>
<a name="l00545"></a>00545 <span class="comment">      netInputSignalToHiddenLayer[0] </span>
<a name="l00546"></a>00546 <span class="comment">      = multilayerPerceptron-&gt;calculateNetInputSignalToHiddenLayer(0, inputSignal);</span>
<a name="l00547"></a>00547 <span class="comment"></span>
<a name="l00548"></a>00548 <span class="comment">      outputSignalFromHiddenLayer[0] </span>
<a name="l00549"></a>00549 <span class="comment">      = multilayerPerceptron-&gt;calculateOutputSignalFromHiddenLayer(0, netInputSignalToHiddenLayer[0]);</span>
<a name="l00550"></a>00550 <span class="comment"></span>
<a name="l00551"></a>00551 <span class="comment">      outputSignalDerivativeFromHiddenLayer[0] </span>
<a name="l00552"></a>00552 <span class="comment">      = multilayerPerceptron-&gt;calculateOutputSignalDerivativeFromHiddenLayer(0, netInputSignalToHiddenLayer[0]);</span>
<a name="l00553"></a>00553 <span class="comment">  </span>
<a name="l00554"></a>00554 <span class="comment">      for(int hiddenLayer = 1; hiddenLayer &lt; numberOfHiddenLayers; hiddenLayer++)</span>
<a name="l00555"></a>00555 <span class="comment">      {</span>
<a name="l00556"></a>00556 <span class="comment">         netInputSignalToHiddenLayer[hiddenLayer] = multilayerPerceptron</span>
<a name="l00557"></a>00557 <span class="comment">         -&gt;calculateNetInputSignalToHiddenLayer(hiddenLayer, outputSignalFromHiddenLayer[hiddenLayer-1]);</span>
<a name="l00558"></a>00558 <span class="comment">   </span>
<a name="l00559"></a>00559 <span class="comment">         outputSignalFromHiddenLayer[hiddenLayer] = multilayerPerceptron</span>
<a name="l00560"></a>00560 <span class="comment">         -&gt;calculateOutputSignalFromHiddenLayer(hiddenLayer, netInputSignalToHiddenLayer[hiddenLayer]);</span>
<a name="l00561"></a>00561 <span class="comment"></span>
<a name="l00562"></a>00562 <span class="comment">         outputSignalDerivativeFromHiddenLayer[hiddenLayer] = multilayerPerceptron</span>
<a name="l00563"></a>00563 <span class="comment">         -&gt;calculateOutputSignalDerivativeFromHiddenLayer(hiddenLayer, netInputSignalToHiddenLayer[hiddenLayer]);         </span>
<a name="l00564"></a>00564 <span class="comment">      }</span>
<a name="l00565"></a>00565 <span class="comment"></span>
<a name="l00566"></a>00566 <span class="comment">      // Get net input signal to output layer</span>
<a name="l00567"></a>00567 <span class="comment"></span>
<a name="l00568"></a>00568 <span class="comment">      netInputSignalToOutputLayer = multilayerPerceptron</span>
<a name="l00569"></a>00569 <span class="comment">      -&gt;calculateNetInputSignalToOutputLayer(outputSignalFromHiddenLayer[numberOfHiddenLayers-1]);</span>
<a name="l00570"></a>00570 <span class="comment"></span>
<a name="l00571"></a>00571 <span class="comment">      // Get actual output signal from output layer</span>
<a name="l00572"></a>00572 <span class="comment"></span>
<a name="l00573"></a>00573 <span class="comment">      Vector&lt;double&gt; outputSignal = multilayerPerceptron-&gt;calculateOutputSignal(netInputSignalToOutputLayer);</span>
<a name="l00574"></a>00574 <span class="comment"></span>
<a name="l00575"></a>00575 <span class="comment">      // Get actual output signal derivative from output layer</span>
<a name="l00576"></a>00576 <span class="comment"></span>
<a name="l00577"></a>00577 <span class="comment">      Vector&lt;double&gt; outputSignalDerivative</span>
<a name="l00578"></a>00578 <span class="comment">      = multilayerPerceptron-&gt;calculateOutputSignalDerivative(netInputSignalToOutputLayer);</span>
<a name="l00579"></a>00579 <span class="comment"></span>
<a name="l00580"></a>00580 <span class="comment">      // Postprocess output signal from the neural network to get output</span>
<a name="l00581"></a>00581 <span class="comment">     </span>
<a name="l00582"></a>00582 <span class="comment">      Vector&lt;double&gt; output = multilayerPerceptron-&gt;postprocessOutputSignal(outputSignal);</span>
<a name="l00583"></a>00583 <span class="comment">      // Actual target</span>
<a name="l00584"></a>00584 <span class="comment"></span>
<a name="l00585"></a>00585 <span class="comment">      target = targetData.getRow(i);</span>
<a name="l00586"></a>00586 <span class="comment">         </span>
<a name="l00587"></a>00587 <span class="comment">      switch(preAndPostProcessingMethod)</span>
<a name="l00588"></a>00588 <span class="comment">      {</span>
<a name="l00589"></a>00589 <span class="comment">         case MultilayerPerceptron::None:</span>
<a name="l00590"></a>00590 <span class="comment">         {</span>
<a name="l00591"></a>00591 <span class="comment">            outputError = outputSignalDerivative*2.0*(output - target);</span>
<a name="l00592"></a>00592 <span class="comment">         }//end none</span>
<a name="l00593"></a>00593 <span class="comment">         break;</span>
<a name="l00594"></a>00594 <span class="comment"></span>
<a name="l00595"></a>00595 <span class="comment">         case MultilayerPerceptron::MeanAndStandardDeviation:</span>
<a name="l00596"></a>00596 <span class="comment">         {</span>
<a name="l00597"></a>00597 <span class="comment">            outputError = outputSignalDerivative*2.0*(output - target)*standardDeviationOfOutputVariables;</span>
<a name="l00598"></a>00598 <span class="comment">         }//end mean and standard deviation</span>
<a name="l00599"></a>00599 <span class="comment">         break;</span>
<a name="l00600"></a>00600 <span class="comment"></span>
<a name="l00601"></a>00601 <span class="comment">         case MultilayerPerceptron::MinimumAndMaximum:</span>
<a name="l00602"></a>00602 <span class="comment">         {</span>
<a name="l00603"></a>00603 <span class="comment">            outputError = outputSignalDerivative*2.0*(output-target)</span>
<a name="l00604"></a>00604 <span class="comment">                         *0.5*(maximumOfOutputVariables-minimumOfOutputVariables);</span>
<a name="l00605"></a>00605 <span class="comment">         }//end minimum and maximum</span>
<a name="l00606"></a>00606 <span class="comment">         break;</span>
<a name="l00607"></a>00607 <span class="comment">      }</span>
<a name="l00608"></a>00608 <span class="comment"></span>
<a name="l00609"></a>00609 <span class="comment">      // Backpropagate the errors of the output units to obtain the error for each hidden unit </span>
<a name="l00610"></a>00610 <span class="comment"></span>
<a name="l00611"></a>00611 <span class="comment">      double sum = 0.0;</span>
<a name="l00612"></a>00612 <span class="comment">     </span>
<a name="l00613"></a>00613 <span class="comment">      for(int j = 0; j &lt; numbersOfHiddenNeurons[0]; j++)</span>
<a name="l00614"></a>00614 <span class="comment">      {</span>
<a name="l00615"></a>00615 <span class="comment">         sum = 0.0;</span>
<a name="l00616"></a>00616 <span class="comment"></span>
<a name="l00617"></a>00617 <span class="comment">         for(int k = 0; k &lt; numberOfOutputs; k++)</span>
<a name="l00618"></a>00618 <span class="comment">         {</span>
<a name="l00619"></a>00619 <span class="comment">            Vector&lt;double&gt; synapticWeights = outputLayer[k].getSynapticWeights();</span>
<a name="l00620"></a>00620 <span class="comment"></span>
<a name="l00621"></a>00621 <span class="comment">            sum += (synapticWeights[j])*outputError[k];</span>
<a name="l00622"></a>00622 <span class="comment">         }</span>
<a name="l00623"></a>00623 <span class="comment"></span>
<a name="l00624"></a>00624 <span class="comment">         netInputSignalToHiddenLayer[0][j] = hiddenLayers[0][j].calculateNetInputSignal(inputSignal);</span>
<a name="l00625"></a>00625 <span class="comment">         </span>
<a name="l00626"></a>00626 <span class="comment">         outputSignalDerivativeFromHiddenLayer[0][j] </span>
<a name="l00627"></a>00627 <span class="comment">         = hiddenLayers[0][j].calculateOutputSignalDerivative(netInputSignalToHiddenLayer[j]);</span>
<a name="l00628"></a>00628 <span class="comment"></span>
<a name="l00629"></a>00629 <span class="comment">         hiddenError[j] = outputSignalDerivativeFromHiddenLayer[j]*sum;</span>
<a name="l00630"></a>00630 <span class="comment">      }</span>
<a name="l00631"></a>00631 <span class="comment"></span>
<a name="l00632"></a>00632 <span class="comment">      // Hidden layer</span>
<a name="l00633"></a>00633 <span class="comment"></span>
<a name="l00634"></a>00634 <span class="comment">      for(int j = 0; j &lt; numbersOfHiddenNeurons[0]; j++)</span>
<a name="l00635"></a>00635 <span class="comment">      {</span>
<a name="l00636"></a>00636 <span class="comment">         // Bias</span>
<a name="l00637"></a>00637 <span class="comment"></span>
<a name="l00638"></a>00638 <span class="comment">         //gradient[index] += hiddenError[j];</span>
<a name="l00639"></a>00639 <span class="comment">         jacobian[i][index] += hiddenError[0][j];</span>
<a name="l00640"></a>00640 <span class="comment">         index++;</span>
<a name="l00641"></a>00641 <span class="comment"></span>
<a name="l00642"></a>00642 <span class="comment">         // Synaptic weights</span>
<a name="l00643"></a>00643 <span class="comment"></span>
<a name="l00644"></a>00644 <span class="comment">         Vector&lt;double&gt; synapticWeights = hiddenLayers[0][j].getSynapticWeights();</span>
<a name="l00645"></a>00645 <span class="comment"></span>
<a name="l00646"></a>00646 <span class="comment">         for(int k = 0; k &lt; numberOfInputs; k++)</span>
<a name="l00647"></a>00647 <span class="comment">         {</span>
<a name="l00648"></a>00648 <span class="comment">            //gradient[index] += hiddenError[j]*inputSignal[k];</span>
<a name="l00649"></a>00649 <span class="comment">            jacobian[i][index] += hiddenError[0][j]*inputSignal[k];</span>
<a name="l00650"></a>00650 <span class="comment"></span>
<a name="l00651"></a>00651 <span class="comment">            index++;   </span>
<a name="l00652"></a>00652 <span class="comment">         }</span>
<a name="l00653"></a>00653 <span class="comment">      }</span>
<a name="l00654"></a>00654 <span class="comment"></span>
<a name="l00655"></a>00655 <span class="comment">      // Output layer</span>
<a name="l00656"></a>00656 <span class="comment"></span>
<a name="l00657"></a>00657 <span class="comment">      for(int j = 0; j &lt; numberOfOutputs; j++)</span>
<a name="l00658"></a>00658 <span class="comment">      {</span>
<a name="l00659"></a>00659 <span class="comment">         // Bias</span>
<a name="l00660"></a>00660 <span class="comment"></span>
<a name="l00661"></a>00661 <span class="comment">         //gradient[index] += outputError[j];</span>
<a name="l00662"></a>00662 <span class="comment">         jacobian[i][index] += outputError[j];</span>
<a name="l00663"></a>00663 <span class="comment">         index++;</span>
<a name="l00664"></a>00664 <span class="comment"></span>
<a name="l00665"></a>00665 <span class="comment">         // Synaptic weights</span>
<a name="l00666"></a>00666 <span class="comment"></span>
<a name="l00667"></a>00667 <span class="comment">         for(int k = 0; k &lt; numbersOfHiddenNeurons[0]; k++)</span>
<a name="l00668"></a>00668 <span class="comment">         {</span>
<a name="l00669"></a>00669 <span class="comment">            //gradient[index] += outputSignalFromHiddenLayer[k]*outputError[j];</span>
<a name="l00670"></a>00670 <span class="comment">            jacobian[i][index] += outputSignalFromHiddenLayer[0][k]*outputError[j];</span>
<a name="l00671"></a>00671 <span class="comment">            index++;</span>
<a name="l00672"></a>00672 <span class="comment">         }</span>
<a name="l00673"></a>00673 <span class="comment">      }</span>
<a name="l00674"></a>00674 <span class="comment"></span>
<a name="l00675"></a>00675 <span class="comment">  }</span>
<a name="l00676"></a>00676 <span class="comment">*/</span>
<a name="l00677"></a>00677    <span class="keywordflow">return</span>(jacobian);
<a name="l00678"></a>00678 }
<a name="l00679"></a>00679 
<a name="l00680"></a>00680 
<a name="l00681"></a>00681 <span class="comment">// Matrix&lt;double&gt; calculateJacobian(void) method</span>
<a name="l00682"></a>00682 
<a name="l00688"></a>00688 
<a name="l00689"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#f579e39007e3ccc6e380cda5bda05b3f">00689</a> <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#f579e39007e3ccc6e380cda5bda05b3f">SumSquaredError::calculateJacobianTest</a>(<span class="keywordtype">void</span>)
<a name="l00690"></a>00690 {
<a name="l00691"></a>00691    <span class="comment">// Multilayer perceptron stuff</span>
<a name="l00692"></a>00692 
<a name="l00693"></a>00693    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> neuralParameters = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#ff440e1405f1e5f3e4bfa4bdd228199f">getNeuralParameters</a>();
<a name="l00694"></a>00694    <span class="keywordtype">int</span> numberOfNeuralParameters = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#0a8cf51981e66e3b4992940506efbde6">getNumberOfNeuralParameters</a>();
<a name="l00695"></a>00695 
<a name="l00696"></a>00696     <span class="comment">// Input target data set stuff</span>
<a name="l00697"></a>00697 
<a name="l00698"></a>00698    <span class="keywordtype">int</span> numberOfSamples = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#f5d20749c6fe94e29dda02adb1f763d2" title="This method returns the number of samples in the input-target data set.">getNumberOfSamples</a>();
<a name="l00699"></a>00699 
<a name="l00700"></a>00700    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> jacobian(numberOfSamples, numberOfNeuralParameters);
<a name="l00701"></a>00701 
<a name="l00702"></a>00702    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> column(numberOfNeuralParameters);
<a name="l00703"></a>00703 
<a name="l00704"></a>00704    <span class="keywordflow">switch</span>(<a class="code" href="class_flood_1_1_objective_functional.html#f3e6d6b2a888fa6c5a15cd4acf9be98a" title="Numerical differentiation methods enumeration.">numericalDifferentiationMethod</a>)   
<a name="l00705"></a>00705    {
<a name="l00706"></a>00706       <span class="keywordflow">case</span> <a class="code" href="class_flood_1_1_objective_functional.html#5bfa6f5387ac02dffd9437c3985c81c69918f4b70586e67985fe737fd4c2f4b7">ForwardDifferences</a>:
<a name="l00707"></a>00707       {
<a name="l00708"></a>00708          <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squaredErrors = <a class="code" href="class_flood_1_1_sum_squared_error.html#880ab72fe9bcef1e4d1b2398f4c9b2a9">calculateSquaredErrors</a>(); 
<a name="l00709"></a>00709          <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squaredErrorsForward(numberOfSamples);
<a name="l00710"></a>00710 
<a name="l00711"></a>00711          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; numberOfNeuralParameters; j++)
<a name="l00712"></a>00712          {
<a name="l00713"></a>00713             <span class="comment">// Perturbate neural parameters</span>
<a name="l00714"></a>00714 
<a name="l00715"></a>00715             neuralParameters[j] += <a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>;
<a name="l00716"></a>00716             <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7802aa985cdc2b5606216dc0b304829d">setNeuralParameters</a>(neuralParameters);
<a name="l00717"></a>00717 
<a name="l00718"></a>00718             <span class="comment">// Calculate squared errors forward</span>
<a name="l00719"></a>00719 
<a name="l00720"></a>00720             squaredErrorsForward = <a class="code" href="class_flood_1_1_sum_squared_error.html#880ab72fe9bcef1e4d1b2398f4c9b2a9">calculateSquaredErrors</a>();
<a name="l00721"></a>00721 
<a name="l00722"></a>00722             <span class="comment">// Restart biases and synaptic weights</span>
<a name="l00723"></a>00723 
<a name="l00724"></a>00724             neuralParameters[j] -= <a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>;
<a name="l00725"></a>00725             <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7802aa985cdc2b5606216dc0b304829d">setNeuralParameters</a>(neuralParameters);
<a name="l00726"></a>00726 
<a name="l00727"></a>00727             <span class="comment">// Calculate Jacobian elements</span>
<a name="l00728"></a>00728                         
<a name="l00729"></a>00729             <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; numberOfSamples; i++)
<a name="l00730"></a>00730             {
<a name="l00731"></a>00731                jacobian[i][j] = (squaredErrorsForward[i] - squaredErrors[i])/<a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>;
<a name="l00732"></a>00732             }
<a name="l00733"></a>00733          }
<a name="l00734"></a>00734 
<a name="l00735"></a>00735       }<span class="comment">// end forward differences</span>
<a name="l00736"></a>00736       <span class="keywordflow">break</span>;
<a name="l00737"></a>00737 
<a name="l00738"></a>00738       <span class="keywordflow">case</span> <a class="code" href="class_flood_1_1_objective_functional.html#5bfa6f5387ac02dffd9437c3985c81c6d8e753089d5cfb8a92b9499d59fc064d">CentralDifferences</a>:
<a name="l00739"></a>00739       {
<a name="l00740"></a>00740          <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squaredErrorsForward(numberOfSamples);
<a name="l00741"></a>00741          <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squaredErrorsBackward(numberOfSamples);
<a name="l00742"></a>00742 
<a name="l00743"></a>00743          <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = 0; j &lt; numberOfNeuralParameters; j++)
<a name="l00744"></a>00744          {
<a name="l00745"></a>00745             <span class="comment">// Perturbate neural parameters</span>
<a name="l00746"></a>00746 
<a name="l00747"></a>00747             neuralParameters[j] += <a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>;
<a name="l00748"></a>00748             <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7802aa985cdc2b5606216dc0b304829d">setNeuralParameters</a>(neuralParameters);
<a name="l00749"></a>00749 
<a name="l00750"></a>00750                         <span class="comment">// Calculate squared errors     </span>
<a name="l00751"></a>00751  
<a name="l00752"></a>00752             squaredErrorsForward = <a class="code" href="class_flood_1_1_sum_squared_error.html#880ab72fe9bcef1e4d1b2398f4c9b2a9">calculateSquaredErrors</a>();
<a name="l00753"></a>00753  
<a name="l00754"></a>00754             <span class="comment">// Restart neural parameters</span>
<a name="l00755"></a>00755 
<a name="l00756"></a>00756             neuralParameters[j] -= <a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>;
<a name="l00757"></a>00757             <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7802aa985cdc2b5606216dc0b304829d">setNeuralParameters</a>(neuralParameters);
<a name="l00758"></a>00758 
<a name="l00759"></a>00759                         <span class="comment">// Perturbate neural parameters</span>
<a name="l00760"></a>00760 
<a name="l00761"></a>00761             neuralParameters[j] -= <a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>;
<a name="l00762"></a>00762             <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7802aa985cdc2b5606216dc0b304829d">setNeuralParameters</a>(neuralParameters);
<a name="l00763"></a>00763 
<a name="l00764"></a>00764             <span class="comment">// Calculate squared errors     </span>
<a name="l00765"></a>00765  
<a name="l00766"></a>00766             squaredErrorsBackward = <a class="code" href="class_flood_1_1_sum_squared_error.html#880ab72fe9bcef1e4d1b2398f4c9b2a9">calculateSquaredErrors</a>();
<a name="l00767"></a>00767  
<a name="l00768"></a>00768             <span class="comment">// Restart neural parameters</span>
<a name="l00769"></a>00769 
<a name="l00770"></a>00770             neuralParameters[j] += <a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>;
<a name="l00771"></a>00771             <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#7802aa985cdc2b5606216dc0b304829d">setNeuralParameters</a>(neuralParameters);
<a name="l00772"></a>00772 
<a name="l00773"></a>00773             <span class="comment">// Calculate Jacobian elements</span>
<a name="l00774"></a>00774 
<a name="l00775"></a>00775             <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; numberOfSamples; i++)
<a name="l00776"></a>00776             {
<a name="l00777"></a>00777                jacobian[i][j] = (squaredErrorsForward[i] - squaredErrorsBackward[i])/(2.0*<a class="code" href="class_flood_1_1_objective_functional.html#f735cdc889dc42d19bb78aa7a0f518c0" title="Epsilon value for the calculation of the objective function gradient with numerical...">numericalEpsilon</a>);
<a name="l00778"></a>00778             }
<a name="l00779"></a>00779          }
<a name="l00780"></a>00780       }<span class="comment">// end central differences</span>
<a name="l00781"></a>00781       <span class="keywordflow">break</span>;
<a name="l00782"></a>00782    }
<a name="l00783"></a>00783 
<a name="l00784"></a>00784 
<a name="l00785"></a>00785    <span class="keywordflow">return</span>(jacobian);
<a name="l00786"></a>00786 }
<a name="l00787"></a>00787 
<a name="l00788"></a>00788 
<a name="l00789"></a>00789 <span class="comment">// Vector&lt;double&gt; calculateSquaredErrors(void) method</span>
<a name="l00790"></a>00790 
<a name="l00794"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#880ab72fe9bcef1e4d1b2398f4c9b2a9">00794</a> 
<a name="l00795"></a>00795 <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_flood_1_1_sum_squared_error.html#880ab72fe9bcef1e4d1b2398f4c9b2a9">SumSquaredError::calculateSquaredErrors</a>(<span class="keywordtype">void</span>)
<a name="l00796"></a>00796 {
<a name="l00797"></a>00797    <span class="keywordtype">int</span> numberOfInputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f727b7059d919a636e04ca0692f0b8bd">getNumberOfInputs</a>();
<a name="l00798"></a>00798    <span class="keywordtype">int</span> numberOfOutputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#55eda41ce2ec7aa063e6854a13143d4a">getNumberOfOutputs</a>();
<a name="l00799"></a>00799 
<a name="l00800"></a>00800    <span class="comment">// Input-target data set</span>
<a name="l00801"></a>00801 
<a name="l00802"></a>00802    <span class="keywordtype">int</span> numberOfSamples = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#f5d20749c6fe94e29dda02adb1f763d2" title="This method returns the number of samples in the input-target data set.">getNumberOfSamples</a>();
<a name="l00803"></a>00803    <span class="keywordtype">int</span> numberOfInputVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#9006d1b87b0bb9590eb28439d9d953c4" title="This method returns the number of input variables of the input-target data set.">getNumberOfInputVariables</a>();
<a name="l00804"></a>00804    <span class="keywordtype">int</span> numberOfTargetVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#503d1eeb47faeb6415e4b3ec76dc4620" title="This method returns the number of target variables of the input-target data set.">getNumberOfTargetVariables</a>();
<a name="l00805"></a>00805 
<a name="l00806"></a>00806    <span class="keywordflow">if</span>(numberOfInputs != numberOfInputVariables || numberOfOutputs != numberOfTargetVariables)
<a name="l00807"></a>00807    {
<a name="l00808"></a>00808       std::cout &lt;&lt; std::endl
<a name="l00809"></a>00809                 &lt;&lt; <span class="stringliteral">"Flood Error SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00810"></a>00810                 &lt;&lt; <span class="stringliteral">"double calculateSquaredErrors(void) method."</span> &lt;&lt; std::endl
<a name="l00811"></a>00811                 &lt;&lt; <span class="stringliteral">"Number of inputs and outputs in multilayer perceptron must be equal to number of input and "</span>
<a name="l00812"></a>00812                 &lt;&lt; <span class="stringliteral">"output variables in input-target data set."</span> 
<a name="l00813"></a>00813                 &lt;&lt; std::endl &lt;&lt; std::endl;
<a name="l00814"></a>00814 
<a name="l00815"></a>00815       exit(1);
<a name="l00816"></a>00816    }
<a name="l00817"></a>00817 
<a name="l00818"></a>00818    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; inputData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#55a414aad1000ba3df7a24fb9b60bc1d" title="This method returns a Matrix containing the input data of the data set.">getInputData</a>();
<a name="l00819"></a>00819    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a>&amp; targetData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#dfa520af76ebbdd4344ba62de1072bb7" title="This method returns a Matrix containing the target data of the data set.">getTargetData</a>();
<a name="l00820"></a>00820 
<a name="l00821"></a>00821    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> squaredErrors(numberOfSamples);
<a name="l00822"></a>00822 
<a name="l00823"></a>00823    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(numberOfInputs);
<a name="l00824"></a>00824    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(numberOfOutputs);
<a name="l00825"></a>00825    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> target(numberOfTargetVariables);
<a name="l00826"></a>00826 
<a name="l00827"></a>00827    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; numberOfSamples; i++)
<a name="l00828"></a>00828    {
<a name="l00829"></a>00829       <span class="comment">// Input vector</span>
<a name="l00830"></a>00830 
<a name="l00831"></a>00831       input = inputData.<a class="code" href="class_flood_1_1_matrix.html#f357ced2467777941490e3ae1982f6d3" title="This method returns the row i of the matrix.">getRow</a>(i);
<a name="l00832"></a>00832 
<a name="l00833"></a>00833       <span class="comment">// Output vector</span>
<a name="l00834"></a>00834 
<a name="l00835"></a>00835       output = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#493a7a9c89c4f9de4819c102e09fa717">calculateOutput</a>(input);
<a name="l00836"></a>00836 
<a name="l00837"></a>00837       <span class="comment">// Target vector</span>
<a name="l00838"></a>00838 
<a name="l00839"></a>00839       target = targetData.<a class="code" href="class_flood_1_1_matrix.html#f357ced2467777941490e3ae1982f6d3" title="This method returns the row i of the matrix.">getRow</a>(i);
<a name="l00840"></a>00840 
<a name="l00841"></a>00841       <span class="comment">// Squared error</span>
<a name="l00842"></a>00842       
<a name="l00843"></a>00843       squaredErrors[i] = (output - target).dot(output - target);
<a name="l00844"></a>00844    }
<a name="l00845"></a>00845 
<a name="l00846"></a>00846    <span class="keywordflow">return</span>(squaredErrors);
<a name="l00847"></a>00847 }
<a name="l00848"></a>00848 
<a name="l00849"></a>00849 
<a name="l00850"></a>00850 <span class="comment">// void saveInputTargetAndOutput(char*) method</span>
<a name="l00851"></a>00851 
<a name="l00856"></a><a class="code" href="class_flood_1_1_sum_squared_error.html#a8aa54a985cddfc5402168f59951cda6">00856</a> 
<a name="l00857"></a>00857 <span class="keywordtype">void</span> <a class="code" href="class_flood_1_1_sum_squared_error.html#a8aa54a985cddfc5402168f59951cda6">SumSquaredError::saveInputTargetAndOutput</a>(<span class="keywordtype">char</span>* filename)
<a name="l00858"></a>00858 {
<a name="l00859"></a>00859    <span class="keywordtype">int</span> numberOfInputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#f727b7059d919a636e04ca0692f0b8bd">getNumberOfInputs</a>();
<a name="l00860"></a>00860    <span class="keywordtype">int</span> numberOfOutputs = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#55eda41ce2ec7aa063e6854a13143d4a">getNumberOfOutputs</a>();
<a name="l00861"></a>00861 
<a name="l00862"></a>00862    <span class="keywordtype">int</span> numberOfSamples = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#f5d20749c6fe94e29dda02adb1f763d2" title="This method returns the number of samples in the input-target data set.">getNumberOfSamples</a>();
<a name="l00863"></a>00863    <span class="keywordtype">int</span> numberOfInputVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#9006d1b87b0bb9590eb28439d9d953c4" title="This method returns the number of input variables of the input-target data set.">getNumberOfInputVariables</a>();
<a name="l00864"></a>00864    <span class="keywordtype">int</span> numberOfTargetVariables = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#503d1eeb47faeb6415e4b3ec76dc4620" title="This method returns the number of target variables of the input-target data set.">getNumberOfTargetVariables</a>();
<a name="l00865"></a>00865 
<a name="l00866"></a>00866    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> inputData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#55a414aad1000ba3df7a24fb9b60bc1d" title="This method returns a Matrix containing the input data of the data set.">getInputData</a>();
<a name="l00867"></a>00867    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> targetData = <a class="code" href="class_flood_1_1_sum_squared_error.html#7859996155901640921e60d7ba453484" title="Pointer to an input-target data set object.">inputTargetDataSet</a>-&gt;<a class="code" href="class_flood_1_1_input_target_data_set.html#dfa520af76ebbdd4344ba62de1072bb7" title="This method returns a Matrix containing the target data of the data set.">getTargetData</a>();
<a name="l00868"></a>00868 
<a name="l00869"></a>00869    <a class="code" href="class_flood_1_1_matrix.html">Matrix&lt;double&gt;</a> outputData(numberOfSamples, numberOfOutputs);
<a name="l00870"></a>00870 
<a name="l00871"></a>00871    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> input(numberOfInputs);
<a name="l00872"></a>00872    <a class="code" href="class_flood_1_1_vector.html">Vector&lt;double&gt;</a> output(numberOfOutputs);
<a name="l00873"></a>00873 
<a name="l00874"></a>00874    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> sample = 0; sample &lt; numberOfSamples; sample++)
<a name="l00875"></a>00875    {
<a name="l00876"></a>00876       input = inputData.<a class="code" href="class_flood_1_1_matrix.html#f357ced2467777941490e3ae1982f6d3" title="This method returns the row i of the matrix.">getRow</a>(sample);
<a name="l00877"></a>00877 
<a name="l00878"></a>00878       output = <a class="code" href="class_flood_1_1_objective_functional.html#7dd10e9c667d300106da2778b498acfc" title="Pointer to a multilayer perceptron object.">multilayerPerceptron</a>-&gt;<a class="code" href="class_flood_1_1_multilayer_perceptron.html#493a7a9c89c4f9de4819c102e09fa717">calculateOutput</a>(input);
<a name="l00879"></a>00879 
<a name="l00880"></a>00880       outputData.<a class="code" href="class_flood_1_1_matrix.html#53129e5f2b419a799fe6e1580d8ab664">setRow</a>(sample, output);
<a name="l00881"></a>00881    }
<a name="l00882"></a>00882 
<a name="l00883"></a>00883    std::fstream file; 
<a name="l00884"></a>00884 
<a name="l00885"></a>00885    file.open(filename, std::ios::out);
<a name="l00886"></a>00886 
<a name="l00887"></a>00887    <span class="comment">// Control sentence</span>
<a name="l00888"></a>00888 
<a name="l00889"></a>00889    <span class="keywordflow">if</span>(!file.is_open())
<a name="l00890"></a>00890    {
<a name="l00891"></a>00891       std::cout &lt;&lt; std::endl
<a name="l00892"></a>00892                 &lt;&lt; <span class="stringliteral">"Flood Error: SumSquaredError class."</span> &lt;&lt; std::endl
<a name="l00893"></a>00893                 &lt;&lt; <span class="stringliteral">"void saveInputTargetAndOutput(char*) method."</span> &lt;&lt; std::endl
<a name="l00894"></a>00894                 &lt;&lt; <span class="stringliteral">"Cannot open input-target-output data file."</span> &lt;&lt; std::endl
<a name="l00895"></a>00895                 &lt;&lt; std::endl;
<a name="l00896"></a>00896 
<a name="l00897"></a>00897       exit(1);
<a name="l00898"></a>00898    }
<a name="l00899"></a>00899    <span class="keywordflow">else</span>
<a name="l00900"></a>00900    {
<a name="l00901"></a>00901       <span class="keywordflow">if</span>(<a class="code" href="class_flood_1_1_objective_functional.html#6c2d9a6f6d36f69b92cca85b274b8fef" title="Display messages to screen.">display</a>)
<a name="l00902"></a>00902       {
<a name="l00903"></a>00903          std::cout &lt;&lt; std::endl
<a name="l00904"></a>00904                    &lt;&lt; <span class="stringliteral">"Saving input-target-output to data file..."</span> &lt;&lt; std::endl;
<a name="l00905"></a>00905       }
<a name="l00906"></a>00906    }
<a name="l00907"></a>00907 
<a name="l00908"></a>00908    <span class="comment">// Write file header</span>
<a name="l00909"></a>00909  
<a name="l00910"></a>00910    file &lt;&lt; <span class="stringliteral">"% Flood Neural Network. Input-target-output data file."</span> &lt;&lt; std::endl
<a name="l00911"></a>00911         &lt;&lt; <span class="stringliteral">"% 1 - Input data"</span> &lt;&lt; std::endl
<a name="l00912"></a>00912         &lt;&lt; <span class="stringliteral">"% 2 - Target data"</span> &lt;&lt; std::endl
<a name="l00913"></a>00913         &lt;&lt; <span class="stringliteral">"% 3 - Output data"</span> &lt;&lt; std::endl
<a name="l00914"></a>00914         &lt;&lt; std::endl;
<a name="l00915"></a>00915 
<a name="l00916"></a>00916    <span class="comment">// Write file data    </span>
<a name="l00917"></a>00917 
<a name="l00918"></a>00918    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> sample = 0; sample &lt; numberOfSamples; sample++)
<a name="l00919"></a>00919    {
<a name="l00920"></a>00920       <span class="comment">// Write sample input data</span>
<a name="l00921"></a>00921 
<a name="l00922"></a>00922       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; numberOfInputVariables; i++)
<a name="l00923"></a>00923       {
<a name="l00924"></a>00924          file &lt;&lt; inputData[sample][i] &lt;&lt; <span class="stringliteral">" "</span>;
<a name="l00925"></a>00925       }
<a name="l00926"></a>00926 
<a name="l00927"></a>00927       <span class="comment">// Write sample target data</span>
<a name="l00928"></a>00928 
<a name="l00929"></a>00929       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; numberOfTargetVariables; i++)
<a name="l00930"></a>00930       {
<a name="l00931"></a>00931          file &lt;&lt; targetData[sample][i] &lt;&lt; <span class="stringliteral">" "</span>;
<a name="l00932"></a>00932       }
<a name="l00933"></a>00933 
<a name="l00934"></a>00934       <span class="comment">// Write sample output data</span>
<a name="l00935"></a>00935 
<a name="l00936"></a>00936       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; numberOfOutputs; i++)
<a name="l00937"></a>00937       {
<a name="l00938"></a>00938          file &lt;&lt; outputData[sample][i] &lt;&lt; <span class="stringliteral">" "</span>;
<a name="l00939"></a>00939       }
<a name="l00940"></a>00940 
<a name="l00941"></a>00941       file &lt;&lt; std::endl;
<a name="l00942"></a>00942    }
<a name="l00943"></a>00943 
<a name="l00944"></a>00944    file &lt;&lt; std::endl;
<a name="l00945"></a>00945 
<a name="l00946"></a>00946    file.close();
<a name="l00947"></a>00947 }
<a name="l00948"></a>00948 
<a name="l00949"></a>00949 }
<a name="l00950"></a>00950 
<a name="l00951"></a>00951 
<a name="l00952"></a>00952 <span class="comment">// Flood: An Open Source Neural Networks C++ Library.</span>
<a name="l00953"></a>00953 <span class="comment">// Copyright (C) 2005-2008 Roberto Lopez </span>
<a name="l00954"></a>00954 <span class="comment">//</span>
<a name="l00955"></a>00955 <span class="comment">// This library is free software; you can redistribute it and/or</span>
<a name="l00956"></a>00956 <span class="comment">// modify it under the s of the GNU Lesser General Public</span>
<a name="l00957"></a>00957 <span class="comment">// License as published by the Free Software Foundation; either</span>
<a name="l00958"></a>00958 <span class="comment">// version 2.1 of the License, or any later version.</span>
<a name="l00959"></a>00959 <span class="comment">//</span>
<a name="l00960"></a>00960 <span class="comment">// This library is distributed in the hope that it will be useful,</span>
<a name="l00961"></a>00961 <span class="comment">// but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<a name="l00962"></a>00962 <span class="comment">// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU</span>
<a name="l00963"></a>00963 <span class="comment">// Lesser General Public License for more details.</span>
<a name="l00964"></a>00964 
<a name="l00965"></a>00965 <span class="comment">// You should have received a copy of the GNU Lesser General Public</span>
<a name="l00966"></a>00966 <span class="comment">// License along with this library; if not, write to the Free Software</span>
<a name="l00967"></a>00967 <span class="comment">// Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA</span>
</pre></div></div>
<hr size="1"><address style="text-align: right;"><small>Generated on Thu Dec 11 13:28:11 2008 for Flood by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.5 </small></address>
</body>
</html>
